{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import pandas as pd\n",
    "from lexnlp.extract.en.entities import nltk_re\n",
    "from lexnlp.nlp.en.segments import sentences\n",
    "from lexnlp.utils import parse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = join('..','data','interim','sfcr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f)) and f[-3:]=='txt']\n",
    "documents = []\n",
    "for file_name in txt_files:\n",
    "    file = open(join(DATA_PATH, file_name), \"rb\")\n",
    "    text = file.read().decode('utf-8')\n",
    "    file.close()\n",
    "    #text = text.replace(\"\\n\", \" \")\n",
    "    documents.append(text)\n",
    "    \n",
    "pickle_files = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f)) and f[-6:]=='pickle']\n",
    "df = pd.DataFrame()\n",
    "for file_name in pickle_files:\n",
    "    df = df.append(pd.read_pickle(join(DATA_PATH, file_name)), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of documents: \" + str(len(documents)))\n",
    "print(\"Number of sentences: \" + str(len(df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get companies (nltk approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_re performs a complex regular expression for finding company entities\n",
    "\n",
    "l = list(nltk_re.get_companies(documents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accounting firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dutch accounting firms are supervised by the AFM. It publishes a register with accounting firms: https://www.afm.nl/en/professionals/registers/vergunningenregisters/accountantsorganisaties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file directly downloaded from AFM website\n",
    "f = join('..','dictionary','nl','AFM','accountantsorganisaties.csv')\n",
    "df_accounting = pd.read_csv(f, encoding = 'latin-1', sep= ';').set_index('Naam organisatie')\n",
    "# additional file for aliases of firm names (for example EY instead of Ernst & Young Accountants)\n",
    "f = join('..','dictionary','nl','AFM','accountantsorganisaties-alias.csv')\n",
    "alias = pd.read_csv(f, sep = ',', encoding = 'latin-1').set_index('Naam organisatie')\n",
    "df_accounting = df_accounting.join(alias).reset_index()\n",
    "\n",
    "parse_columns = ('Naam organisatie', 'Korte naam', 'Afkorting')\n",
    "result_columns = {'Naam organisatie': 'name'}\n",
    "preformed_entity = {'entity_type': 'accounting firm', \n",
    "                    'source'     : 'AFM', \n",
    "                    'country'    : 'NL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results1 = pd.DataFrame()\n",
    "for idx, document in enumerate(documents):\n",
    "    for sentence in sentences.get_sentence_list(document):\n",
    "        items = list(parse_df.DataframeEntityParser(df_accounting, parse_columns, result_columns, preformed_entity).get_entities_from_text(sentence))\n",
    "        for i in items:\n",
    "            df_results1 = df_results1.append(pd.DataFrame(columns = ['file name']+list(i.keys())+['text'], \n",
    "                                                          data = [[txt_files[idx]]+list(i.values())+[sentence]]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results2 = pd.DataFrame()\n",
    "for sent_id in df.index:\n",
    "    sentence = df.loc[sent_id,'text']\n",
    "    items = list(parse_df.DataframeEntityParser(df_accounting, parse_columns, result_columns, preformed_entity).get_entities_from_text(sentence))\n",
    "    for i in items:\n",
    "        df_results2 = df_results2.append(pd.DataFrame(columns = list(df.loc[sent_id].index) + list(i.keys()), \n",
    "                                                      data = [list(df.loc[sent_id].values) + list(i.values())]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance undertakings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIOPA's register includes all European insurance undertakings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = join('..','dictionary','common','EIOPA','DATINS_Export_637110803393817886.csv')\n",
    "df_insurers = pd.read_csv(f, encoding = 'latin-1', sep = ';')\n",
    "df_insurers = df_insurers[df_insurers['Name of NCA']=='De Nederlandsche Bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_columns = ('International Name', 'Official name of the entity')\n",
    "result_columns = {'International Name': 'name', 'Home Country': 'country'}\n",
    "preformed_entity = {'entity_type': 'insurance undertaking', \n",
    "                    'source'     : 'EIOPA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "for idx, document in enumerate(documents[0:4]):\n",
    "    for sentence in sentences.get_sentence_list(document):\n",
    "        items = list(parse_df.DataframeEntityParser(df_insurers, parse_columns, result_columns, preformed_entity).get_entities_from_text(sentence))\n",
    "        for i in items:\n",
    "            df_results = df_results.append(pd.DataFrame(columns = ['file name']+list(i.keys())+['sentence'], \n",
    "                                                        data = [[txt_files[idx]]+list(i.values())+[str(sentence)]]))\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
